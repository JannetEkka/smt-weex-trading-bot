{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SMT-WEEX Notebook 4: Hyperparameter Tuning & Final Model\n",
        "**Project:** smt-weex-2025\n",
        "**Author:** Jannet Ekka\n",
        "\n",
        "This notebook:\n",
        "1. RandomizedSearchCV for hyperparameter tuning\n",
        "2. Retrain best model with optimal params\n",
        "3. Final evaluation\n",
        "4. Export production model to GCS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q catboost xgboost lightgbm scikit-learn pandas numpy matplotlib seaborn google-cloud-storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "PROJECT_ID = 'smt-weex-2025'\n",
        "BUCKET = 'smt-weex-2025-models'\n",
        "\n",
        "!gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, make_scorer, confusion_matrix, balanced_accuracy_score\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data from GCS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download from GCS\n",
        "!gsutil cp gs://{BUCKET}/data/data_splits.npz /content/\n",
        "!gsutil cp gs://{BUCKET}/data/feature_config.json /content/\n",
        "!mkdir -p /content/models\n",
        "!gsutil cp gs://{BUCKET}/models/initial/label_encoder.pkl /content/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data splits\n",
        "splits = np.load('/content/data_splits.npz')\n",
        "X_train, y_train = splits['X_train'], splits['y_train']\n",
        "X_val, y_val = splits['X_val'], splits['y_val']\n",
        "X_test, y_test = splits['X_test'], splits['y_test']\n",
        "\n",
        "# Combine train + val for tuning (will use cross-validation)\n",
        "X_trainval = np.vstack([X_train, X_val])\n",
        "y_trainval = np.concatenate([y_train, y_val])\n",
        "\n",
        "# Load feature config\n",
        "with open('/content/feature_config.json', 'r') as f:\n",
        "    config = json.load(f)\n",
        "FEATURES = config['features']\n",
        "\n",
        "# Load label encoder\n",
        "with open('/content/models/label_encoder.pkl', 'rb') as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "label_mapping = {i: label for i, label in enumerate(le.classes_)}\n",
        "labels = list(label_mapping.values())\n",
        "n_classes = len(label_mapping)\n",
        "\n",
        "print(f\"Train+Val: {len(X_trainval)}, Test: {len(X_test)}\")\n",
        "print(f\"Features: {len(FEATURES)}\")\n",
        "print(f\"Classes: {n_classes} - {labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. CatBoost Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define search space for CatBoost\n",
        "catboost_param_dist = {\n",
        "    'iterations': randint(200, 800),\n",
        "    'learning_rate': uniform(0.01, 0.15),\n",
        "    'depth': randint(3, 8),\n",
        "    'l2_leaf_reg': uniform(1, 10),\n",
        "    'border_count': randint(32, 128),\n",
        "    'bagging_temperature': uniform(0, 1),\n",
        "    'random_strength': uniform(0, 5)\n",
        "}\n",
        "\n",
        "# Scoring metric\n",
        "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
        "\n",
        "# Cross-validation strategy\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"CatBoost search space defined\")\n",
        "print(f\"Parameters: {list(catboost_param_dist.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "print(\"=\" * 60)\n",
        "print(\"CatBoost Hyperparameter Tuning (30 iterations)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "catboost_base = CatBoostClassifier(\n",
        "    loss_function='MultiClass',\n",
        "    random_seed=42,\n",
        "    verbose=0,\n",
        "    auto_class_weights='Balanced'\n",
        ")\n",
        "\n",
        "catboost_search = RandomizedSearchCV(\n",
        "    catboost_base,\n",
        "    param_distributions=catboost_param_dist,\n",
        "    n_iter=30,\n",
        "    scoring=f1_macro_scorer,\n",
        "    cv=cv,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "catboost_search.fit(X_trainval, y_trainval)\n",
        "\n",
        "print(f\"\\nBest F1 (macro) CV score: {catboost_search.best_score_:.4f}\")\n",
        "print(f\"Best params: {catboost_search.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. XGBoost Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define search space for XGBoost\n",
        "xgb_param_dist = {\n",
        "    'n_estimators': randint(200, 800),\n",
        "    'learning_rate': uniform(0.01, 0.15),\n",
        "    'max_depth': randint(3, 8),\n",
        "    'min_child_weight': randint(1, 10),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'colsample_bytree': uniform(0.6, 0.4),\n",
        "    'gamma': uniform(0, 3),\n",
        "    'reg_alpha': uniform(0, 2),\n",
        "    'reg_lambda': uniform(0, 3)\n",
        "}\n",
        "\n",
        "print(\"XGBoost search space defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "print(\"=\" * 60)\n",
        "print(\"XGBoost Hyperparameter Tuning (30 iterations)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "xgb_base = XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=n_classes,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "xgb_search = RandomizedSearchCV(\n",
        "    xgb_base,\n",
        "    param_distributions=xgb_param_dist,\n",
        "    n_iter=30,\n",
        "    scoring=f1_macro_scorer,\n",
        "    cv=cv,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "xgb_search.fit(X_trainval, y_trainval)\n",
        "\n",
        "print(f\"\\nBest F1 (macro) CV score: {xgb_search.best_score_:.4f}\")\n",
        "print(f\"Best params: {xgb_search.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Compare Tuned Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuned_models = {\n",
        "    'CatBoost_tuned': catboost_search.best_estimator_,\n",
        "    'XGBoost_tuned': xgb_search.best_estimator_\n",
        "}\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TUNED MODEL COMPARISON ON TEST SET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "tuned_results = {}\n",
        "for name, model in tuned_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    tuned_results[name] = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),\n",
        "        'f1_macro': f1_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'f1_weighted': f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    }\n",
        "    print(f\"\\n{name}:\")\n",
        "    for metric, val in tuned_results[name].items():\n",
        "        print(f\"  {metric}: {val:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select best tuned model\n",
        "best_tuned_name = max(tuned_results, key=lambda x: tuned_results[x]['f1_macro'])\n",
        "best_tuned_model = tuned_models[best_tuned_name]\n",
        "print(f\"\\nBest tuned model: {best_tuned_name}\")\n",
        "print(f\"F1 macro: {tuned_results[best_tuned_name]['f1_macro']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Final Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_final = best_tuned_model.predict(X_test)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"FINAL MODEL: {best_tuned_name}\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_final, target_names=labels, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_final)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.title(f'{best_tuned_name} - Final Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/final_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved confusion matrix to /content/final_confusion_matrix.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance for final model\n",
        "if 'CatBoost' in best_tuned_name:\n",
        "    importance = best_tuned_model.get_feature_importance()\n",
        "else:\n",
        "    importance = best_tuned_model.feature_importances_\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': FEATURES,\n",
        "    'importance': importance\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_n = min(20, len(FEATURES))\n",
        "plt.barh(range(top_n), importance_df['importance'].head(top_n).values, color='steelblue')\n",
        "plt.yticks(range(top_n), importance_df['feature'].head(top_n).values)\n",
        "plt.xlabel('Importance')\n",
        "plt.title(f'Top {top_n} Features - {best_tuned_name}')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/final_feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Export Production Model to GCS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('/content/production_model', exist_ok=True)\n",
        "\n",
        "# Save model in appropriate format\n",
        "if 'CatBoost' in best_tuned_name:\n",
        "    best_tuned_model.save_model('/content/production_model/whale_classifier_final.cbm')\n",
        "    model_format = 'cbm'\n",
        "else:\n",
        "    with open('/content/production_model/whale_classifier_final.pkl', 'wb') as f:\n",
        "        pickle.dump(best_tuned_model, f)\n",
        "    model_format = 'pkl'\n",
        "\n",
        "print(f\"Model saved as {model_format}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get best params based on model type\n",
        "if 'CatBoost' in best_tuned_name:\n",
        "    best_params = catboost_search.best_params_\n",
        "else:\n",
        "    best_params = xgb_search.best_params_\n",
        "\n",
        "# Convert numpy types to native Python types for JSON serialization\n",
        "def convert_to_native(obj):\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, dict):\n",
        "        return {k: convert_to_native(v) for k, v in obj.items()}\n",
        "    return obj\n",
        "\n",
        "# Create model metadata\n",
        "model_metadata = {\n",
        "    'model_name': best_tuned_name,\n",
        "    'model_format': model_format,\n",
        "    'best_params': convert_to_native(best_params),\n",
        "    'features': FEATURES,\n",
        "    'n_features': len(FEATURES),\n",
        "    'classes': labels,\n",
        "    'n_classes': n_classes,\n",
        "    'metrics': convert_to_native(tuned_results[best_tuned_name]),\n",
        "    'cv_score': float(catboost_search.best_score_ if 'CatBoost' in best_tuned_name else xgb_search.best_score_),\n",
        "    'timestamp': str(datetime.now()),\n",
        "    'version': 'v1.0'\n",
        "}\n",
        "\n",
        "with open('/content/production_model/model_metadata.json', 'w') as f:\n",
        "    json.dump(model_metadata, f, indent=2)\n",
        "\n",
        "# Copy label encoder\n",
        "with open('/content/production_model/label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "# Copy feature config\n",
        "with open('/content/production_model/feature_config.json', 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(\"All artifacts saved\")\n",
        "print(f\"\\nModel metadata:\")\n",
        "print(json.dumps(model_metadata, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload to GCS\n",
        "!gsutil -m cp -r /content/production_model/* gs://{BUCKET}/models/production/\n",
        "!gsutil cp /content/final_confusion_matrix.png gs://{BUCKET}/results/\n",
        "!gsutil cp /content/final_feature_importance.png gs://{BUCKET}/results/\n",
        "\n",
        "print(f\"\\nProduction model uploaded to gs://{BUCKET}/models/production/\")\n",
        "print(f\"Results uploaded to gs://{BUCKET}/results/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List uploaded files\n",
        "print(\"\\n=== GCS Contents ===\")\n",
        "!gsutil ls gs://{BUCKET}/models/production/\n",
        "print(\"\")\n",
        "!gsutil ls gs://{BUCKET}/results/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Quick Test: Load and Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify model can be loaded and used\n",
        "print(\"=== Testing Production Model ===\")\n",
        "\n",
        "if model_format == 'cbm':\n",
        "    test_model = CatBoostClassifier()\n",
        "    test_model.load_model('/content/production_model/whale_classifier_final.cbm')\n",
        "else:\n",
        "    with open('/content/production_model/whale_classifier_final.pkl', 'rb') as f:\n",
        "        test_model = pickle.load(f)\n",
        "\n",
        "# Test prediction\n",
        "sample_idx = 0\n",
        "sample_features = X_test[sample_idx:sample_idx+1]\n",
        "pred = test_model.predict(sample_features)\n",
        "proba = test_model.predict_proba(sample_features)\n",
        "\n",
        "print(f\"Sample prediction: {label_mapping[int(pred[0])]}\")\n",
        "print(f\"True label: {label_mapping[y_test[sample_idx]]}\")\n",
        "print(f\"Probabilities: {dict(zip(labels, proba[0].round(4)))}\")\n",
        "print(\"\\nModel loaded and working correctly!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Hyperparameter tuning completed:\n",
        "1. RandomizedSearchCV (30 iterations) for CatBoost and XGBoost\n",
        "2. 5-fold stratified cross-validation\n",
        "3. Optimized for F1 (macro)\n",
        "4. Final model exported to GCS\n",
        "\n",
        "**Production Model Location:** `gs://smt-weex-2025-models/models/production/`\n",
        "\n",
        "**Files:**\n",
        "- `whale_classifier_final.cbm` (or .pkl) - trained model\n",
        "- `model_metadata.json` - hyperparameters, metrics, feature list\n",
        "- `label_encoder.pkl` - for encoding/decoding labels\n",
        "- `feature_config.json` - feature names and config\n",
        "\n",
        "**Next Steps:**\n",
        "1. Deploy to Vertex AI for online prediction\n",
        "2. Integrate with Gemini 2.5 Flash for signal validation\n",
        "3. Connect to WEEX API for trading"
      ]
    }
  ]
}
