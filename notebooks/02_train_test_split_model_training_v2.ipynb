{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SMT-WEEX Notebook 2: Model Training (v2)\n",
        "**Project:** smt-weex-2025\n",
        "**Author:** Jannet Ekka\n",
        "\n",
        "**Updates in v2:**\n",
        "- CatBoost: 80/20 split, NO early stopping (per research)\n",
        "- Other models: 70/10/20 split with early stopping\n",
        "- Added 5-fold Stratified CV for all models\n",
        "- Fixed CatBoost underfitting issue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q catboost xgboost lightgbm scikit-learn pandas numpy matplotlib seaborn google-cloud-storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "PROJECT_ID = 'smt-weex-2025'\n",
        "BUCKET = 'smt-weex-2025-models'\n",
        "\n",
        "!gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix, make_scorer\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Cleaned Data from GCS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gsutil cp gs://{BUCKET}/data/whale_features_cleaned.csv /content/\n",
        "!gsutil cp gs://{BUCKET}/data/feature_config.json /content/\n",
        "\n",
        "df = pd.read_csv('/content/whale_features_cleaned.csv')\n",
        "\n",
        "with open('/content/feature_config.json', 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "FEATURES = config['features']\n",
        "TARGET = config['target']\n",
        "\n",
        "print(f\"Loaded {len(df)} samples, {len(FEATURES)} features\")\n",
        "print(f\"Categories: {df[TARGET].value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare X and y\n",
        "X = df[FEATURES].values\n",
        "y_raw = df[TARGET].values\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_raw)\n",
        "\n",
        "# Save label mapping\n",
        "label_mapping = {i: label for i, label in enumerate(le.classes_)}\n",
        "n_classes = len(label_mapping)\n",
        "\n",
        "print(\"Label mapping:\")\n",
        "for idx, label in label_mapping.items():\n",
        "    count = (y == idx).sum()\n",
        "    print(f\"  {idx}: {label} ({count} samples)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Splits\n",
        "\n",
        "**Strategy:**\n",
        "- CatBoost: 80/20 train/test (no validation, no early stopping per research)\n",
        "- Other models: 70/10/20 train/val/test (with early stopping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Common test set for all models (20%)\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.20, \n",
        "    random_state=42, \n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# For CatBoost: use all trainval as training (80/20 split)\n",
        "X_train_cb = X_trainval\n",
        "y_train_cb = y_trainval\n",
        "\n",
        "# For other models: split trainval into train/val (70/10/20 overall)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_trainval, y_trainval,\n",
        "    test_size=0.125,  # 0.125 * 0.8 = 0.1 (10% of total)\n",
        "    random_state=42,\n",
        "    stratify=y_trainval\n",
        ")\n",
        "\n",
        "print(\"=== Data Splits ===\")\n",
        "print(f\"CatBoost Train: {len(X_train_cb)} ({len(X_train_cb)/len(X)*100:.1f}%)\")\n",
        "print(f\"Other Train:    {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"Other Val:      {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)\")\n",
        "print(f\"Test (all):     {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check stratification\n",
        "print(\"\\n=== Class Distribution in Splits ===\")\n",
        "for name, y_subset in [('CatBoost Train', y_train_cb), ('Other Train', y_train), \n",
        "                        ('Val', y_val), ('Test', y_test)]:\n",
        "    unique, counts = np.unique(y_subset, return_counts=True)\n",
        "    dist = {label_mapping[u]: int(c) for u, c in zip(unique, counts)}\n",
        "    print(f\"{name:15s}: {dist}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store models and results\n",
        "models = {}\n",
        "results_holdout = {}\n",
        "results_cv = {}\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"Evaluate model and return metrics\"\"\"\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision_macro': precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'recall_macro': recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'f1_macro': f1_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'f1_weighted': f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    }, y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Training\n",
        "\n",
        "### 5.1 CatBoost (Primary - Per Research Recommendations)\n",
        "- 80/20 split, NO early stopping\n",
        "- depth=5, learning_rate=0.03, l2_leaf_reg=3\n",
        "- auto_class_weights='Balanced'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Training CatBoost (80/20 split, NO early stopping)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "catboost_model = CatBoostClassifier(\n",
        "    iterations=300,           # Fixed iterations, no early stopping\n",
        "    learning_rate=0.03,       # Per research\n",
        "    depth=5,                  # Per research (4-5)\n",
        "    l2_leaf_reg=3,            # Per research\n",
        "    loss_function='MultiClass',\n",
        "    eval_metric='TotalF1:average=Macro',\n",
        "    random_seed=42,\n",
        "    verbose=50,\n",
        "    auto_class_weights='Balanced',  # Handle imbalance\n",
        "    # NO early_stopping_rounds\n",
        ")\n",
        "\n",
        "# Train on 80% data (no validation set)\n",
        "catboost_model.fit(X_train_cb, y_train_cb)\n",
        "\n",
        "models['CatBoost'] = catboost_model\n",
        "print(\"\\nCatBoost training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 XGBoost (70/10/20 with early stopping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Training XGBoost (70/10/20 split, with early stopping)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Calculate sample weights\n",
        "sample_weights = compute_sample_weight('balanced', y_train)\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=4,\n",
        "    reg_alpha=1,              # L1 regularization\n",
        "    reg_lambda=3,             # L2 regularization (heavy per research)\n",
        "    objective='multi:softmax',\n",
        "    num_class=n_classes,\n",
        "    random_state=42,\n",
        "    early_stopping_rounds=50,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "xgb_model.fit(\n",
        "    X_train, y_train,\n",
        "    sample_weight=sample_weights,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    verbose=100\n",
        ")\n",
        "\n",
        "models['XGBoost'] = xgb_model\n",
        "print(\"\\nXGBoost training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Random Forest (70/10/20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Training Random Forest\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=3,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "models['RandomForest'] = rf_model\n",
        "print(\"Random Forest training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 LightGBM (70/10/20 - Not Recommended per Research)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Training LightGBM (WARNING: Not ideal for <10K samples per research)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "lgbm_model = LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=4,\n",
        "    num_leaves=15,            # Conservative for small data\n",
        "    reg_alpha=1,\n",
        "    reg_lambda=3,\n",
        "    objective='multiclass',\n",
        "    num_class=n_classes,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced',\n",
        "    verbosity=-1\n",
        ")\n",
        "\n",
        "lgbm_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)]\n",
        ")\n",
        "\n",
        "models['LightGBM'] = lgbm_model\n",
        "print(\"LightGBM training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Holdout Test Set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"HOLDOUT TEST SET EVALUATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for name, model in models.items():\n",
        "    metrics, y_pred = evaluate_model(model, X_test, y_test)\n",
        "    results_holdout[name] = metrics\n",
        "    \n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Accuracy:          {metrics['accuracy']:.4f}\")\n",
        "    print(f\"  Precision (macro): {metrics['precision_macro']:.4f}\")\n",
        "    print(f\"  Recall (macro):    {metrics['recall_macro']:.4f}\")\n",
        "    print(f\"  F1 (macro):        {metrics['f1_macro']:.4f}\")\n",
        "    print(f\"  F1 (weighted):     {metrics['f1_weighted']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Holdout results table\n",
        "holdout_df = pd.DataFrame(results_holdout).T.round(4)\n",
        "print(\"\\n=== Holdout Test Results ===\")\n",
        "print(holdout_df.sort_values('f1_macro', ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 5-Fold Stratified Cross-Validation\n",
        "\n",
        "Per research: Use 5-fold (not 10-fold) to maintain sufficient samples per class in each fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"5-FOLD STRATIFIED CROSS-VALIDATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Use full trainval data for CV (80% of total)\n",
        "X_cv = X_trainval\n",
        "y_cv = y_trainval\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Custom scorer for macro F1\n",
        "f1_macro_scorer = make_scorer(f1_score, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CatBoost 5-fold CV\n",
        "print(\"\\nCatBoost 5-fold CV...\")\n",
        "cb_cv_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_cv, y_cv)):\n",
        "    X_fold_train, X_fold_val = X_cv[train_idx], X_cv[val_idx]\n",
        "    y_fold_train, y_fold_val = y_cv[train_idx], y_cv[val_idx]\n",
        "    \n",
        "    cb_fold = CatBoostClassifier(\n",
        "        iterations=300,\n",
        "        learning_rate=0.03,\n",
        "        depth=5,\n",
        "        l2_leaf_reg=3,\n",
        "        loss_function='MultiClass',\n",
        "        random_seed=42,\n",
        "        verbose=0,\n",
        "        auto_class_weights='Balanced'\n",
        "    )\n",
        "    cb_fold.fit(X_fold_train, y_fold_train)\n",
        "    y_pred = cb_fold.predict(X_fold_val)\n",
        "    score = f1_score(y_fold_val, y_pred, average='macro')\n",
        "    cb_cv_scores.append(score)\n",
        "    print(f\"  Fold {fold+1}: F1={score:.4f}\")\n",
        "\n",
        "results_cv['CatBoost'] = {\n",
        "    'mean': np.mean(cb_cv_scores),\n",
        "    'std': np.std(cb_cv_scores),\n",
        "    'scores': cb_cv_scores\n",
        "}\n",
        "print(f\"  Mean: {np.mean(cb_cv_scores):.4f} (+/- {np.std(cb_cv_scores):.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# XGBoost 5-fold CV\n",
        "print(\"\\nXGBoost 5-fold CV...\")\n",
        "xgb_cv_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_cv, y_cv)):\n",
        "    X_fold_train, X_fold_val = X_cv[train_idx], X_cv[val_idx]\n",
        "    y_fold_train, y_fold_val = y_cv[train_idx], y_cv[val_idx]\n",
        "    \n",
        "    sample_weights_fold = compute_sample_weight('balanced', y_fold_train)\n",
        "    \n",
        "    xgb_fold = XGBClassifier(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.03,\n",
        "        max_depth=4,\n",
        "        reg_alpha=1,\n",
        "        reg_lambda=3,\n",
        "        objective='multi:softmax',\n",
        "        num_class=n_classes,\n",
        "        random_state=42,\n",
        "        verbosity=0\n",
        "    )\n",
        "    xgb_fold.fit(X_fold_train, y_fold_train, sample_weight=sample_weights_fold)\n",
        "    y_pred = xgb_fold.predict(X_fold_val)\n",
        "    score = f1_score(y_fold_val, y_pred, average='macro')\n",
        "    xgb_cv_scores.append(score)\n",
        "    print(f\"  Fold {fold+1}: F1={score:.4f}\")\n",
        "\n",
        "results_cv['XGBoost'] = {\n",
        "    'mean': np.mean(xgb_cv_scores),\n",
        "    'std': np.std(xgb_cv_scores),\n",
        "    'scores': xgb_cv_scores\n",
        "}\n",
        "print(f\"  Mean: {np.mean(xgb_cv_scores):.4f} (+/- {np.std(xgb_cv_scores):.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RandomForest 5-fold CV\n",
        "print(\"\\nRandomForest 5-fold CV...\")\n",
        "rf_cv_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_cv, y_cv)):\n",
        "    X_fold_train, X_fold_val = X_cv[train_idx], X_cv[val_idx]\n",
        "    y_fold_train, y_fold_val = y_cv[train_idx], y_cv[val_idx]\n",
        "    \n",
        "    rf_fold = RandomForestClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=3,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        class_weight='balanced'\n",
        "    )\n",
        "    rf_fold.fit(X_fold_train, y_fold_train)\n",
        "    y_pred = rf_fold.predict(X_fold_val)\n",
        "    score = f1_score(y_fold_val, y_pred, average='macro')\n",
        "    rf_cv_scores.append(score)\n",
        "    print(f\"  Fold {fold+1}: F1={score:.4f}\")\n",
        "\n",
        "results_cv['RandomForest'] = {\n",
        "    'mean': np.mean(rf_cv_scores),\n",
        "    'std': np.std(rf_cv_scores),\n",
        "    'scores': rf_cv_scores\n",
        "}\n",
        "print(f\"  Mean: {np.mean(rf_cv_scores):.4f} (+/- {np.std(rf_cv_scores):.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LightGBM 5-fold CV\n",
        "print(\"\\nLightGBM 5-fold CV...\")\n",
        "lgbm_cv_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_cv, y_cv)):\n",
        "    X_fold_train, X_fold_val = X_cv[train_idx], X_cv[val_idx]\n",
        "    y_fold_train, y_fold_val = y_cv[train_idx], y_cv[val_idx]\n",
        "    \n",
        "    lgbm_fold = LGBMClassifier(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.03,\n",
        "        max_depth=4,\n",
        "        num_leaves=15,\n",
        "        reg_alpha=1,\n",
        "        reg_lambda=3,\n",
        "        objective='multiclass',\n",
        "        num_class=n_classes,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        class_weight='balanced',\n",
        "        verbosity=-1\n",
        "    )\n",
        "    lgbm_fold.fit(X_fold_train, y_fold_train)\n",
        "    y_pred = lgbm_fold.predict(X_fold_val)\n",
        "    score = f1_score(y_fold_val, y_pred, average='macro')\n",
        "    lgbm_cv_scores.append(score)\n",
        "    print(f\"  Fold {fold+1}: F1={score:.4f}\")\n",
        "\n",
        "results_cv['LightGBM'] = {\n",
        "    'mean': np.mean(lgbm_cv_scores),\n",
        "    'std': np.std(lgbm_cv_scores),\n",
        "    'scores': lgbm_cv_scores\n",
        "}\n",
        "print(f\"  Mean: {np.mean(lgbm_cv_scores):.4f} (+/- {np.std(lgbm_cv_scores):.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CV Results Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"5-FOLD CV RESULTS SUMMARY (F1 Macro)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cv_summary = pd.DataFrame({\n",
        "    'Model': list(results_cv.keys()),\n",
        "    'Mean F1': [results_cv[m]['mean'] for m in results_cv],\n",
        "    'Std': [results_cv[m]['std'] for m in results_cv]\n",
        "}).sort_values('Mean F1', ascending=False)\n",
        "\n",
        "print(cv_summary.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Results Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare Holdout vs CV\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"HOLDOUT vs 5-FOLD CV COMPARISON\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "comparison = []\n",
        "for model_name in models.keys():\n",
        "    comparison.append({\n",
        "        'Model': model_name,\n",
        "        'Holdout F1': results_holdout[model_name]['f1_macro'],\n",
        "        'CV Mean F1': results_cv[model_name]['mean'],\n",
        "        'CV Std': results_cv[model_name]['std'],\n",
        "        'Holdout Acc': results_holdout[model_name]['accuracy']\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison).sort_values('CV Mean F1', ascending=False)\n",
        "print(comparison_df.round(4).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Holdout results\n",
        "model_names = list(models.keys())\n",
        "holdout_f1 = [results_holdout[m]['f1_macro'] for m in model_names]\n",
        "cv_f1 = [results_cv[m]['mean'] for m in model_names]\n",
        "cv_std = [results_cv[m]['std'] for m in model_names]\n",
        "\n",
        "x = np.arange(len(model_names))\n",
        "width = 0.35\n",
        "\n",
        "axes[0].bar(x - width/2, holdout_f1, width, label='Holdout', color='steelblue')\n",
        "axes[0].bar(x + width/2, cv_f1, width, label='5-Fold CV', color='coral', yerr=cv_std, capsize=3)\n",
        "axes[0].set_ylabel('F1 Macro')\n",
        "axes[0].set_title('Holdout vs 5-Fold CV (F1 Macro)')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(model_names, rotation=45)\n",
        "axes[0].legend()\n",
        "axes[0].set_ylim(0, 1)\n",
        "\n",
        "# CV scores distribution\n",
        "cv_data = [results_cv[m]['scores'] for m in model_names]\n",
        "axes[1].boxplot(cv_data, labels=model_names)\n",
        "axes[1].set_ylabel('F1 Macro')\n",
        "axes[1].set_title('5-Fold CV Score Distribution')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Best model selection\n",
        "best_holdout = max(results_holdout, key=lambda x: results_holdout[x]['f1_macro'])\n",
        "best_cv = max(results_cv, key=lambda x: results_cv[x]['mean'])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"BEST MODEL SELECTION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Best by Holdout F1:  {best_holdout} ({results_holdout[best_holdout]['f1_macro']:.4f})\")\n",
        "print(f\"Best by CV Mean F1:  {best_cv} ({results_cv[best_cv]['mean']:.4f} +/- {results_cv[best_cv]['std']:.4f})\")\n",
        "\n",
        "# Research target check\n",
        "print(\"\\n--- Research Target Check ---\")\n",
        "print(f\"Expected F1 Macro: 65-75% (per research)\")\n",
        "print(f\"Best Achieved:     {max(results_cv[best_cv]['mean'], results_holdout[best_holdout]['f1_macro'])*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Save Models and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('/content/models', exist_ok=True)\n",
        "\n",
        "# Save CatBoost\n",
        "catboost_model.save_model('/content/models/catboost_whale_classifier.cbm')\n",
        "\n",
        "# Save others as pickle\n",
        "with open('/content/models/xgboost_whale_classifier.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_model, f)\n",
        "\n",
        "with open('/content/models/randomforest_whale_classifier.pkl', 'wb') as f:\n",
        "    pickle.dump(rf_model, f)\n",
        "\n",
        "with open('/content/models/lightgbm_whale_classifier.pkl', 'wb') as f:\n",
        "    pickle.dump(lgbm_model, f)\n",
        "\n",
        "# Save label encoder\n",
        "with open('/content/models/label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "# Save all results\n",
        "all_results = {\n",
        "    'holdout': results_holdout,\n",
        "    'cv': {k: {'mean': v['mean'], 'std': v['std'], 'scores': v['scores']} \n",
        "           for k, v in results_cv.items()},\n",
        "    'best_model_holdout': best_holdout,\n",
        "    'best_model_cv': best_cv,\n",
        "    'label_mapping': label_mapping\n",
        "}\n",
        "\n",
        "with open('/content/models/training_results.json', 'w') as f:\n",
        "    json.dump(all_results, f, indent=2, default=str)\n",
        "\n",
        "print(\"Models and results saved locally\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload to GCS\n",
        "!gsutil -m cp -r /content/models/* gs://{BUCKET}/models/initial/\n",
        "\n",
        "# Save data splits\n",
        "np.savez('/content/data_splits.npz',\n",
        "         X_train_cb=X_train_cb, y_train_cb=y_train_cb,\n",
        "         X_train=X_train, y_train=y_train,\n",
        "         X_val=X_val, y_val=y_val,\n",
        "         X_test=X_test, y_test=y_test)\n",
        "\n",
        "!gsutil cp /content/data_splits.npz gs://{BUCKET}/data/data_splits.npz\n",
        "\n",
        "print(f\"\\nUploaded to gs://{BUCKET}/models/initial/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**Training Complete:**\n",
        "- CatBoost: 80/20 split, 300 iterations, NO early stopping\n",
        "- XGBoost/RF/LightGBM: 70/10/20 split with validation\n",
        "- 5-Fold Stratified CV for all models\n",
        "\n",
        "**Key Findings:**\n",
        "- Best Holdout: [see output]\n",
        "- Best CV: [see output]\n",
        "- Research target (65-75% F1): [see output]\n",
        "\n",
        "**Next:** Run Notebook 03 for detailed evaluation (confusion matrices, feature importance, per-class metrics)"
      ]
    }
  ]
}
